---
description: Streams log events to Apache Kafka
---

<!---
!!!WARNING!!!!

This file is autogenerated! Please do not manually edit this file.
Instead, please modify the contents of `dist/config/schema.toml`.
-->


# kafka sink

![](../../../.gitbook/assets/kafka-sink.svg)


The `kafka` sink streams [`log`][log_event] events to [Apache Kafka][kafka] via the [Kafka protocol][kafka_protocol].

## Example

{% code-tabs %}
{% code-tabs-item title="vector.toml (example)" %}
```coffeescript
[sinks.my_kafka_sink]
  # REQUIRED - General
  type = "kafka"
  inputs = ["my-source-id"]
  bootstrap_servers = "10.14.22.123:9092,10.14.23.332:9092"
  topic = "topic-1234"

  # OPTIONAL - General
  encoding = "json" # no default, one of: json, text
  key_field = "partition_key" # no default
```
{% endcode-tabs-item %}
{% code-tabs-item title="vector.toml (schema)" %}
```coffeescript
[sink.<sink-id>]
  # REQUIRED - General
  type = "<string>"
  inputs = "<string>"
  bootstrap_servers = "<string>"
  topic = "<string>"

  # OPTIONAL - General
  encoding = {json | text}
  key_field = "<string>"
```
{% endcode-tabs-item %}
{% code-tabs-item title="vector.toml (specification)" %}
```coffeescript
[sink.kafka]
  # REQUIRED - General

  # The component type
  type = "kafka"

  # A list of upstream source for more info.
  inputs = ["my-source-id"]

  # A comma-separated list of host and port pairs that are the addresses of the Kafka brokers in a "bootstrap" Kafka cluster that a Kafka client connects to initially to bootstrap itself
  bootstrap_servers = "10.14.22.123:9092,10.14.23.332:9092"

  # The Kafka topic name to write events to.
  topic = "topic-1234"

  # OPTIONAL - General

  # The encoding format used to serialize the events before flushing.
  encoding = "json"
  encoding = "text"

  # The field name to use for the topic key. If unspecified, the key will be randomly generated. If the field does not exist on the event, a blank value will be used.
  key_field = "partition_key"
```
{% endcode-tabs-item %}
{% endcode-tabs %}

## Options

| Key  | Type  | Description |
| :--- | :---: | :---------- |
| **REQUIRED** | | |
| `inputs` | `string` | A list of upstream [source][sources] or [transform][transforms] IDs. See [Config Composition][config_composition] for more info.<br />`required` `example: ["my-source-id"]` |
| `bootstrap_servers` | `string` | A comma-separated list of host and port pairs that are the addresses of the Kafka brokers in a "bootstrap" Kafka cluster that a Kafka client connects to initially to bootstrap itself<br />`required` `example: (see above)` |
| `topic` | `string` | The Kafka topic name to write events to.<br />`required` `example: "topic-1234"` |
| **OPTIONAL** | | |
| `encoding` | `string` | The encoding format used to serialize the events before flushing. See [Encodings](#encodings) for more info.<br />`no default` `enum: "json", "text"` |
| `key_field` | `string` | The field name to use for the topic key. If unspecified, the key will be randomly generated. If the field does not exist on the event, a blank value will be used.<br />`no default` `example: "partition_key"` |

## I/O

The `kafka` sink streams events to [Apache Kafka][kafka] via the [Kafka protocol][kafka_protocol]. The encoding of each event is dictated by the `encoding` option. For example:

The `kafka` sink streams events in a real-time fashion. Each event is encoded as dictated by the `encoding` option. See [Encoding](#encoding) for more info.



## How It Works

### Delivery Guarantee

This component offers an **at least once** delivery guarantee if your
[pipeline is configured to achieve this][at_least_once_delivery].

### Encodings

The `kafka` sink encodes events before flushing. This is controlled via the `encoding` option. Each encoding type is described in more detail below:

| Encoding | Description |
| `json` | The payload will be encoded as a single JSON payload. |
| `text` | The payload will be encoded as new line delimited text, each line representing the value of the `"message"` key. |

### Health Checks

Vector will perform a simple health check against the underlying service before initializing this sink. This ensures that the service is reachable. You can require this check with the `--require-healthy` flag upon [starting][starting] Vector.

### Streaming

Events will be streamed in a real-time, one-by-one fashiong, making
events immediately available. They will not be batched.

## Troubleshooting

The best place to start with troubleshooting is to check the
[Vector logs][monitoring_logs]. This is typically located at
`/var/log/vector.log`, then proceed to follow the
[Troubleshooting Guide][troubleshooting].

If the [Troubleshooting Guide][troubleshooting] does not resolve your
issue, please:

1. Check for any [open sink issues](https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22Sink%3A+kafka%22).
2. [Search the forum][search_forum] for any similar issues.
2. Reach out to the [community][community] for help.

## Resources

* [**Issues**](https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22Sink%3A+kafka%22) - [enhancements](https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22Sink%3A+kafka%22+label%3A%22Type%3A+Enhancement%22) - [bugs](https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22Sink%3A+kafka%22+label%3A%22Type%3A+Bug%22)
* [**Source code**](https://github.com/timberio/vector/tree/master/src/sink/kafka.rs)


[log_event]: "../../../about/data-model.md#log"
[kafka]: "https://kafka.apache.org/"
[kafka_protocol]: "https://kafka.apache.org/protocol"
[sources]: "../../../usage/configuration/sources"
[transforms]: "../../../usage/configuration/transforms"
[config_composition]: "../../../usage/configuration/README.md#composition"
[at_least_once_delivery]: "../../../about/guarantees.md#at-least-once-delivery"
[starting]: "../../../usage/administration/starting.md"
[monitoring_logs]: "../../../administration/moonitoring.md#logs"
[troubleshooting]: "../../../usages/guides/troubleshooting.md"
[search_forum]: "https://forum.vectorproject.io/search?expanded=true"
[community]: "https://vectorproject.io/community"

