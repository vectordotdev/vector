---
description: Batches `log` events to AWS S3 via the `PutObject` API endpoint.
---

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the template located at:

     scripts/generate/templates/docs/usage/configuration/sinks/aws_s3.md.erb
-->

# aws_s3 sink

![][assets.aws_s3_sink]

{% hint style="warning" %}
The `aws_s3` sink is in beta. Please see the current
[enhancements][urls.aws_s3_sink_enhancements] and
[bugs][urls.aws_s3_sink_bugs] for known issues.
We kindly ask that you [add any missing issues][urls.new_aws_s3_sink_issue]
as it will help shape the roadmap of this component.
{% endhint %}

The `aws_s3` sink [batches](#buffers-and-batches) [`log`][docs.data-model.log] events to [AWS S3][urls.aws_s3] via the [`PutObject` API endpoint](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPUT.html).

## Example

{% code-tabs %}
{% code-tabs-item title="vector.toml (simple)" %}
```coffeescript
[sinks.my_sink_id]
  # REQUIRED - General
  type = ["aws_s3", "The name of this component"] # required, type: string, must be: "aws_s3"
  inputs = ["my-source-id"] # required, type: [string], example: ["my-source-id"]
  bucket = "my-bucket" # required, type: string, example: "my-bucket"
  region = "us-east-1" # required, type: string, example: "us-east-1"
  
  # OPTIONAL - Batching
  batch_size = 10490000 # optional, default: 10490000, type: int, unit: bytes
  batch_timeout = 300 # optional, default: 300, type: int, unit: seconds
  
  # OPTIONAL - Object Names
  key_prefix = "date=%F/" # optional, default: "date=%F", type: string
```
{% endcode-tabs-item %}
{% code-tabs-item title="vector.toml (advanced)" %}
```coffeescript
[sinks.my_sink_id]
  # REQUIRED - General
  type = ["aws_s3", "The name of this component"] # required, type: string, must be: "aws_s3"
  inputs = ["my-source-id"] # required, type: [string], example: ["my-source-id"]
  bucket = "my-bucket" # required, type: string, example: "my-bucket"
  region = "us-east-1" # required, type: string, example: "us-east-1"
  
  # OPTIONAL - General
  endpoint = "127.0.0.0:5000" # optional, no default, type: string, example: "127.0.0.0:5000"
  healthcheck = true # optional, default: true, type: bool
  
  # OPTIONAL - Batching
  batch_size = 10490000 # optional, default: 10490000, type: int, unit: bytes
  batch_timeout = 300 # optional, default: 300, type: int, unit: seconds
  
  # OPTIONAL - Object Names
  filename_append_uuid = true # optional, default: true, type: bool
  filename_extension = "log" # optional, default: "log", type: bool
  filename_time_format = "%s" # optional, default: "%s", type: string
  key_prefix = "date=%F/" # optional, default: "date=%F", type: string
  
  # OPTIONAL - Requests
  rate_limit_duration = 1 # optional, default: 1, type: int, unit: seconds
  rate_limit_num = 5 # optional, default: 5, type: int
  request_in_flight_limit = 5 # optional, default: 5, type: int
  request_timeout_secs = 30 # optional, default: 30, type: int, unit: seconds
  retry_attempts = 5 # optional, default: 5, type: int
  retry_backoff_secs = 5 # optional, default: 5, type: int, unit: seconds
  
  # OPTIONAL - Buffer
  [sinks.my_sink_id.buffer]
    type = ["memory", "Stores the sink's buffer in memory. This is more performant (~3x), but less durable. Data will be lost if Vector is restarted abruptly."] # optional, default: "memory", type: string, enum: "memory" or "disk"
    max_size = 104900000 # optional, no default, type: int, unit: bytes, example: 104900000, relevant when type = "disk"
    num_items = 500 # optional, default: 500, type: int, unit: events, relevant when type = "memory"
    when_full = ["block", "Applies back pressure when the buffer is full. This prevents data loss, but will cause data to pile up on the edge."] # optional, default: "block", type: string, enum: "block" or "drop_newest"
```
{% endcode-tabs-item %}
{% endcode-tabs %}

## Options

### batch_size

`optional` `default: 10490000` `type: int` `unit: bytes`

The maximum size of a batch before it is flushed.

### batch_timeout

`optional` `default: 300` `type: int` `unit: seconds`

The maximum age of a batch before it is flushed.

### bucket

`required` `type: string` `example: "my-bucket"`

The S3 bucket name. Do not include a leading `s3://` or a trailing `/`.

### buffer

`optional`

Configures the sink specific buffer.

#### buffer.type

`optional` `default: "memory"` `type: string`

The buffer's type / location. `disk` buffers are persistent and will be retained between restarts.

The field is an enumeration and only accepts the following values:

| Value | Description |
|:------|:------------|
| `"memory"` *(default)* | Stores the sink's buffer in memory. This is more performant (~3x), but less durable. Data will be lost if Vector is restarted abruptly. |
| `"disk"` | Stores the sink's buffer on disk. This is less performance (~3x),  but durable. Data will not be lost between restarts. |

#### buffer.when_full

`optional` `default: "block"` `type: string`

The behavior when the buffer becomes full.

The field is an enumeration and only accepts the following values:

| Value | Description |
|:------|:------------|
| `"block"` *(default)* | Applies back pressure when the buffer is full. This prevents data loss, but will cause data to pile up on the edge. |
| `"drop_newest"` | Drops new data as it's received. This data is lost. This should be used when performance is the highest priority. |

#### buffer.max_size

`optional` `no default` `type: int` `unit: bytes` `example: 104900000`

The maximum size of the buffer on the disk. Only relevant when type = "disk".

#### buffer.num_items

`optional` `default: 500` `type: int` `unit: events`

The maximum number of [events][docs.event] allowed in the buffer. Only relevant when type = "memory".

### endpoint

`optional` `no default` `type: string` `example: "127.0.0.0:5000"`

Custom endpoint for use with AWS-compatible services.

### filename_append_uuid

`optional` `default: true` `type: bool`

Whether or not to append a UUID v4 token to the end of the file. This ensures there are no name collisions high volume use cases.

### filename_extension

`optional` `default: "log"` `type: bool`

The extension to use in the object name.

### filename_time_format

`optional` `default: "%s"` `type: string`

The format of the resulting object file name. [`strftime` specifiers][urls.strftime_specifiers] are supported.

### healthcheck

`optional` `default: true` `type: bool`

Enables/disables the sink healthcheck upon start.

### key_prefix

`optional` `default: "date=%F"` `type: string`

A prefix to apply to all object key names. This should be used to partition your objects, and it's important to end this value with a `/` if you want this to be the root S3 "folder". This option supports dynamic values via [Vector's template syntax][docs.configuration#template-syntax].

### rate_limit_duration

`optional` `default: 1` `type: int` `unit: seconds`

The window used for the `request_rate_limit_num` option

### rate_limit_num

`optional` `default: 5` `type: int`

The maximum number of requests allowed within the `rate_limit_duration` window.

### region

`required` `type: string` `example: "us-east-1"`

The [AWS region][urls.aws_s3_regions] of the target S3 bucket.

### request_in_flight_limit

`optional` `default: 5` `type: int`

The maximum number of in-flight requests allowed at any given time.

### request_timeout_secs

`optional` `default: 30` `type: int` `unit: seconds`

The maximum time a request can take before being aborted. It is highly recommended that you do not lower value below the service's internal timeout, as this could create orphaned requests, pile on retries, and result in deuplicate data downstream.

### retry_attempts

`optional` `default: 5` `type: int`

The maximum number of retries to make for failed requests.

### retry_backoff_secs

`optional` `default: 5` `type: int` `unit: seconds`

The amount of time to wait before attempting a failed request again.

## Input/Output

The `aws_s3` sink batches [`log`][docs.data-model.log] up to the `batch_size` or
`batch_timeout` options. When flushed, Vector will write to [AWS S3][urls.aws_s3]
via the [`PutObject` API
endpoint](https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPUT.html).
The encoding is dictated by the `encoding` option. For example:

```http
POST / HTTP/1.1
Host: kinesis.<region>.<domain>
Content-Length: <byte_size>
Content-Type: application/x-amz-json-1.1
Connection: Keep-Alive 
X-Amz-Target: Kinesis_20131202.PutRecords
{
    "Records": [
        {
            "Data": "<base64_encoded_event>",
            "PartitionKey": "<partition_key>"
        },
        {
            "Data": "<base64_encoded_event>",
            "PartitionKey": "<partition_key>"
        },
        {
            "Data": "<base64_encoded_event>",
            "PartitionKey": "<partition_key>"
        },
    ],
    "StreamName": "<stream_name>"
}
```

## How It Works

### Authentication

Vector checks for AWS credentials in the following order:

1. Environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.
2. The [`credential_process` command][urls.aws_credential_process] in the AWS config file. (usually located at `~/.aws/config`)
3. The [AWS credentials file][urls.aws_credentials_file]. (usually located at `~/.aws/credentials`)
4. The [IAM instance profile][urls.iam_instance_profile]. (will only work if running on an EC2 instance with an instance profile/role)

If credentials are not found the [healtcheck](#healthchecks) will fail and an
error will be [logged][docs.monitoring#logs].

#### Obtaining an access key

In general, we recommend using instance profiles/roles whenever possible. In
cases where this is not possible you can generate an AWS access key for any user
within your AWS account. AWS provides a [detailed guide][urls.aws_access_keys] on
how to do this.

### Buffers & Batches

 
![][assets.sink-flow-partitioned]

The `aws_s3` sink buffers & batches data as
shown in the diagram above. You'll notice that Vector treats these concepts
differently, instead of treating them as global concepts, Vector treats them
as sink specific concepts. This isolates sinks, ensuring services disruptions
are contained and [delivery guarantees][docs.guarantees] are honored.

*Batches* are flushed when 1 of 2 conditions are met:

1. The batch age meets or exceeds the configured `batch_timeout` (default: `300 seconds`).
2. The batch size meets or exceeds the configured `batch_size` (default: `10490000 bytes`).

*Buffers* are controlled via the [`buffer.*`](#buffer) options.

### Columnar Formats

Vector has plans to support column formats, such as ORC and Parquet, in
[`v0.6`][urls.vector_roadmap].

### Delivery Guarantee

This component offers an [**at least once** delivery guarantee][docs.guarantees#at-least-once-delivery]
if your [pipeline is configured to achieve this][docs.guarantees#at-least-once-delivery].

### Environment Variables

Environment variables are supported through all of Vector's configuration.
Simply add `${MY_ENV_VAR}` in your Vector configuration file and the variable
will be replaced before being evaluated.

You can learn more in the [Environment Variables][docs.configuration#environment-variables]
section.

### Health Checks

Health checks ensure that the downstream service is accessible and ready to
accept data. This check is performed upon sink initialization.

If the health check fails an error will be logged and Vector will proceed to
start. If you'd like to exit immediately upon health check failure, you can
pass the `--require-healthy` flag:

```bash
vector --config /etc/vector/vector.toml --require-healthy
```

And finally, if you'd like to disable health checks entirely for this sink
you can set the `healthcheck` option to `false`.

### Object Naming

By default, Vector will name your S3 objects in the following format:

{% code-tabs %}
{% code-tabs-item title="no compression" %}
```
<key_prefix><timestamp>-<uuidv4>.log
```
{% endcode-tabs-item %}
{% code-tabs-item title="gzip" %}
```
<key_prefix><timestamp>-<uuidv4>.log.gz
```
{% endcode-tabs-item %}
{% endcode-tabs %}

For example:

{% code-tabs %}
{% code-tabs-item title="no compression" %}
```
date=2019-06-18/1560886634-fddd7a0e-fad9-4f7e-9bce-00ae5debc563.log
```
{% endcode-tabs-item %}
{% code-tabs-item title="gzip" %}
```
date=2019-06-18/1560886634-fddd7a0e-fad9-4f7e-9bce-00ae5debc563.log.gz
```
{% endcode-tabs-item %}
{% endcode-tabs %}

Vector appends a [UUIDV4][urls.uuidv4] token to ensure there are no name
conflicts in the unlikely event 2 Vector instances are writing data at the same
time.

You can control the resulting name via the `key_prefix`, `filename_time_format`,
and `filename_append_uuid` options.

### Partitioning

Partitioning is controlled via the `key_prefix`
options and allows you to dynamically partition data on the fly.
You'll notice that Vector's [template sytax](#template-syntax) is supported
for these options, enabling you to use field values as the partition's key.

### Rate Limits

Vector offers a few levers to control the rate and volume of requests to the
downstream service. Start with the `rate_limit_duration` and `rate_limit_num`
options to ensure Vector does not exceed the specified number of requests in
the specified window. You can further control the pace at which this window is
saturated with the `request_in_flight_limit` option, which will guarantee no
more than the specified number of requests are in-flight at any given time.

Please note, Vector's defaults are carefully chosen and it should be rare that
you need to adjust these. If you found a good reason to do so please share it
with the Vector team by [opening an issie][urls.new_aws_s3_sink_issue].

### Retry Policy

Vector will retry failed requests (status == `429`, >= `500`, and != `501`).
Other responses will _not_ be retried. You can control the number of retry
attempts and backoff rate with the `retry_attempts` and `retry_backoff_secs` options.

### Searching

Storing log data in S3 is a powerful strategy for persisting log data. Mainly
because data on S3 is searchable. And [AWS Athena][urls.aws_athena] makes this
easier than ever.

#### Athena

1. Head over to the [Athena console][urls.aws_athena_console].

2. Create a new table, replace the `<...>` variables as needed:

    ```sql
    CREATE EXTERNAL TABLE logs (
      timestamp string,
      message string,
      host string
    )   
    PARTITIONED BY (date string)
    ROW FORMAT  serde 'org.apache.hive.hcatalog.data.JsonSerDe'
    with serdeproperties ( 'paths'='timestamp, message, host' )
    LOCATION 's3://<region>.<key_prefix>';
    ```

3. Discover your partitions by running the following query:

    ```sql
    MSCK REPAIR TABLE logs
    ```

4. Query your data:

    ```sql
    SELECT host, COUNT(*)
    FROM logs
    GROUP BY host
    ```

Vector has plans to support [columnar formats](#columnar-formats) in
[`v0.6`][urls.vector_roadmap] which will allows for very fast and efficient querying on
S3.

### Template Syntax

The `key_prefix` options
support [Vector's template syntax][docs.configuration#template-syntax],
enabling dynamic values derived from the event's data. This syntax accepts
[strftime specifiers][urls.strftime_specifiers] as well as the
`{{ field_name }}` syntax for accessing event fields. For example:

{% code-tabs %}
{% code-tabs-item title="vector.toml" %}
```coffeescript
[sinks.my_aws_s3_sink_id]
  # ...
  key_prefix = "date=%F/"
  key_prefix = "date=%F/hour=%H/"
  key_prefix = "year=%Y/month=%m/day=%d/"
  key_prefix = "application_id={{ application_id }}/date=%F/"
  # ...
```
{% endcode-tabs-item %}
{% endcode-tabs %}

You can read more about the complete syntax in the
[template syntax section][docs.configuration#template-syntax].

## Troubleshooting

The best place to start with troubleshooting is to check the
[Vector logs][docs.monitoring#logs]. This is typically located at
`/var/log/vector.log`, then proceed to follow the
[Troubleshooting Guide][docs.troubleshooting].

If the [Troubleshooting Guide][docs.troubleshooting] does not resolve your
issue, please:

1. Check for any [open `aws_s3_sink` issues][urls.aws_s3_sink_issues].
2. If encountered a bug, please [file a bug report][urls.new_aws_s3_sink_bug].
3. If encountered a missing feature, please [file a feature request][urls.new_aws_s3_sink_enhancement].
4. If you need help, [join our chat/forum community][urls.vector_chat]. You can post a question and search previous questions.

## Resources

* [**Issues**][urls.aws_s3_sink_issues] - [enhancements][urls.aws_s3_sink_enhancements] - [bugs][urls.aws_s3_sink_bugs]
* [**Source code**][urls.aws_s3_sink_source]
* [**Service Limits**][urls.aws_s3_service_limits]


[assets.aws_s3_sink]: ../../../assets/aws_s3-sink.svg
[assets.sink-flow-partitioned]: ../../../assets/sink-flow-partitioned.svg
[docs.configuration#environment-variables]: ../../../usage/configuration#environment-variables
[docs.configuration#template-syntax]: ../../../usage/configuration#template-syntax
[docs.data-model.log]: ../../../about/data-model/log.md
[docs.event]: ../../../setup/getting-started/sending-your-first-event.md
[docs.guarantees#at-least-once-delivery]: ../../../about/guarantees.md#at-least-once-delivery
[docs.guarantees]: ../../../about/guarantees.md
[docs.monitoring#logs]: ../../../usage/administration/monitoring.md#logs
[docs.troubleshooting]: ../../../usage/guides/troubleshooting.md
[urls.aws_access_keys]: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html
[urls.aws_athena]: https://aws.amazon.com/athena/
[urls.aws_athena_console]: https://console.aws.amazon.com/athena/home
[urls.aws_credential_process]: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-sourcing-external.html
[urls.aws_credentials_file]: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html
[urls.aws_s3]: https://aws.amazon.com/s3/
[urls.aws_s3_regions]: https://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region
[urls.aws_s3_service_limits]: https://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html
[urls.aws_s3_sink_bugs]: https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22sink%3A+aws_s3%22+label%3A%22Type%3A+bug%22
[urls.aws_s3_sink_enhancements]: https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22sink%3A+aws_s3%22+label%3A%22Type%3A+enhancement%22
[urls.aws_s3_sink_issues]: https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22sink%3A+aws_s3%22
[urls.aws_s3_sink_source]: https://github.com/timberio/vector/tree/master/src/sinks/aws_s3.rs
[urls.iam_instance_profile]: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html
[urls.new_aws_s3_sink_bug]: https://github.com/timberio/vector/issues/new?labels=sink%3A+aws_s3&labels=Type%3A+bug
[urls.new_aws_s3_sink_enhancement]: https://github.com/timberio/vector/issues/new?labels=sink%3A+aws_s3&labels=Type%3A+enhancement
[urls.new_aws_s3_sink_issue]: https://github.com/timberio/vector/issues/new?labels=sink%3A+aws_s3
[urls.strftime_specifiers]: https://docs.rs/chrono/0.3.1/chrono/format/strftime/index.html
[urls.uuidv4]: https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_(random)
[urls.vector_chat]: https://chat.vector.dev
[urls.vector_roadmap]: https://github.com/timberio/vector/milestones?direction=asc&sort=due_date&state=open
