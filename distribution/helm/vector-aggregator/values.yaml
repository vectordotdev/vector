# Default values for vector-aggregator.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

global:
  clusterDomain: "cluster.local"
  kubeDNSAddress: "kube-dns.kube-system"
# Additional labels to add to all resources
# commonLabels:
#   app.kubernetes.io/component: aggregator

secrets:
  generic: {}
    # Each Key/Value will be added to a Secret resource
    # Values should be entered base64 encoded (examples below are "REPLACE_ME" encoded)
    # NOTE: Don't commit unencrypted secrets to git!
    # awsAccessKeyId: "UkVQTEFDRV9NRQo="
    # awsSecretAccessKey: "UkVQTEFDRV9NRQo="

image:
  repository: timberio/vector
  pullPolicy: IfNotPresent
  # Overrides the image tag, the default is `{image.version}-{image.base}`.
  tag: ""
  # Overrides the image version, the default is the Chart appVersion.
  version: ""
  base: "debian"

# Image pull secrets to use at the `Pod`s managed by `StatefulSet`.
imagePullSecrets: []
#  - myRegistryCredentialSecretName

# Override the chart name used in templates.
nameOverride: ""
# Override the full chart name (name prefixed with release name) used in
# templates.
fullnameOverride: ""

podManagementPolicy: Parallel

replicas: 1

serviceAccount:
  # Specifies whether a service account should be created.
  create: true
  # Annotations to add to the service account.
  annotations: {}
  # The name of the service account to use.
  # If not set and `create` is true, a name is generated using the `fullname`
  # template.
  name: ""
  # Automount API credentials for a service account.
  automountServiceAccountToken: true

# Add an annotation to the `Pod`s managed by `StatefulSet` with a random value,
# generated at Helm Chart template evaluation time.
# Enabling this will cause the `Pod`s to be recreated every time the value
# changes - effectively restarting them on each update.
podRollmeAnnotation: false

# Add an annotation to the `Pod`s managed by `StatefulSet` with a checksum of
# the Helm release values (as in `values.yaml` content and `--set` flags).
# Enabling this will cause the `Pod`s to be recreated every time values
# change.
podValuesChecksumAnnotation: false

# Annotations to add to the `Pod`s managed by `StatefulSet`.
podAnnotations: {}

# Labels to add to the `Pod`s managed by `StatefulSet`.
podLabels: {}

# Priority class name to add to the `Pod`s managed by `StatefulSet`.
podPriorityClassName: ""

# PodSecurityContext to set at the `Pod`s managed by `StatefulSet`.
podSecurityContext: {}
  # fsGroup: 2000

# Security context to set at the `vector` container at the `Pod`s managed by
# `StatefulSet`.
securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

# Extra env vars to pass to the `vector` container.
env: []
  # - name: AWS_ACCESS_KEY_ID
  #   valueFrom:
  #     secretKeyRef:
  #       name: vector-aggregator
  #       key: awsAccessKeyId

# Extra arguments to pass to the `vector` container.
args: []
  # - --quiet
  # - --verbose

# Tolerations to set for the `Pod`s managed by `DaemonSet`.
tolerations:
  # This toleration is to have the `DaemonSet` runnable on master nodes.
  # Remove it if your masters can't run pods.
  - key: node-role.kubernetes.io/master
    effect: NoSchedule

# Various tweakables for the `Pod`s managed by `StatefulSet`.
resources: {}
nodeSelector: {}
affinity: {}

# Additional container ports to pass to the `vector` container of the `Pod`s
# managed by `StatefulSet`.
extraContainersPorts: []

# Additional sources to include at the `config-dir` projection of the `Pod`s
# managed by `StatefulSet`.
extraConfigDirSources: []

# Additional volumes to pass to the `Pod`s managed by `StatefulSet`.
extraVolumes: []

# Additional volume mounts to pass to the `vector` container of the `Pod`s
# managed by `StatefulSet`.
extraVolumeMounts: []

# Storage options.
storage:
  # The storage mode to use to store `vector` data.
  # Possible values:
  # - `hostPath`
  # - `managedPersistentVolumeClaim`
  # - `existingPersistentVolumeClaim`
  # - `empty`
  mode: empty

  # Absolute path on the host to store `vector` data.
  # If `mode` is set to anything other than `hostPath` has no effect.
  hostPath: ""

  # Create `PersistentVolumeClaim` via the `volumeClaimTemplates` of
  # the `StatefulSet` to store `vector` data.
  # If `mode` is set to anything other than `managedPersistentVolumeClaim` has
  # no effect.
  managedPersistentVolumeClaim:
    # The size to allocate.
    size: 10Gi
    # If defined, then `storageClassName: <storageClass>`.
    # If set to "-", then `storageClassName: ""`, which disables dynamic
    # provisioning.
    # If undefined or empty (default), then no `storageClassName` spec is set,
    # so the default provisioner will be chosen (gp2 on AWS, standard on
    # GKE, AWS & OpenStack).
    storageClass: ""

    # Additional labels to apply to the created `PersistentVolumeClaim`.
    labels: {}
    # Additional annotations to apply to the created `PersistentVolumeClaim`.
    annotations: {}

  # The name of the existing `PersistentVolumeClaim` to store `vector` data.
  # Useful if you're running in a cluster that requires manually provisioning
  # `PersistentVolume`s and binding them to the `PersistentVolumeClaim`s.
  # If `mode` is set to anything other than `existingPersistentVolumeClaim` has
  # no effect.
  existingPersistentVolumeClaim: ""

rbac:
  # Whether to create rbac resources or not. Disable for non-rbac clusters.
  enabled: false

psp:
  # Whether to create `PodSecurityPolicy` or not.
  enabled: false

# Use Liveness Probe (The Probe is using API endpoint which is disabled by default.
# You have to enable the API in the Config to expose the endpoint.)
livenessProbe: {}
  # httpGet:
  #   path: /health
  #   port: api

# Use Readiness Probe (The Probe is using API endpoint which is disabled by default.
# You have to enable the API in the Config to expose the endpoint.)
readinessProbe: {}
  # httpGet:
  #   path: /health
  #   port: api

# Change DNS Policy
dnsPolicy:

# Custom DNS configuration to be added to vector-agent pods
dnsConfig: {}
  # nameservers:
  #   - 1.2.3.4
  # searches:
  #   - ns1.svc.cluster-domain.example
  #   - my.dns.search.suffix
  # options:
  #   - name: ndots
  #     value: "2"
  #   - name: edns0

# Configuration for both regular and headless `Service`.
service:
  # Service type - defaults to `ClusterIP` (only relevant for the regular service).
  type: "ClusterIP"
  # Additional ports to expose.
  ports: []
    # - name: http
    #   port: 1234
    #   protocol: TCP
    #   targetPort: 1234
    #   nodePort: 1243  # (optional but useful with `service.type` is set to `NodePort`)

# Set this to non-empty value to use existing `ConfigMap` for `vector`, instead
# of using a generated one.
existingConfigMap: ""

# Specify custom contents for the Vector config
# ref: https://vector.dev/docs/reference/configuration/
# Note a complete and valid configuration is required. If used, the deprecated
# configuration keys will be ignored. More information can be found at:
# https://vector.dev/highlights/2021-07-13-helm-customconfig
customConfig: {}
  #  data_dir: "/vector-data-dir"
  #  sources:
  #    host_metrics:
  #    internal_metrics:
  #      type: internal_metrics
  #   vector:
  #     type: vector
  #     address: 0.0.0.0:9000
  #     version: "2"
  #  sinks:
  #    prometheus_sink:
  #      type: prometheus_exporter
  #      inputs: ["internal_metrics"]
  #      address: 0.0.0.0:9090

# Use prometheus-operator `PodMonitor` to opt-in for Prometheus scraping.
# To be used in clusters that rely on prometheus-operator to gather metrics.
# You might want to set `podMonitorSelectorNilUsesHelmValues=false` if you're
# using prometheus-operator Helm chart to allow `PodMonitor` resources
# discovery in all namespaces.
podMonitor:
  # Whether to add the `PodMonitor` resource or not.
  # `prometheus-operator` CRDs are necessary, otherwise you'll get an error.
  enabled: false
  # Additional labels for PodMonitor
  additionalLabels: {}
  # Additional relabelings to include in the `PodMonitor`.
  extraRelabelings: []
  # metricRelabelings to include in the `PodMonitor`.
  metricRelabelings: []

# Global parts of the generated `vector` config.
# DEPRECATED. Use customConfig instead
globalOptions:
  # Specifies the (in-container) data dir used by `vector`.
  dataDir: "/vector-data-dir"

# Schema part of the generated `vector` config.
# DEPRECATED. Use customConfig instead
logSchema:
  hostKey: "host"
  messageKey: "message"
  sourceTypeKey: "source_type"
  timestampKey: "timestamp"

# The Vector API.
# Will be disabled by default.
# DEPRECATED. Use customConfig instead
vectorApi:
  # Turn the Vector API on or off.
  enabled: false
  # The address to listen at.
  address: "0.0.0.0:8686"
  # Enable or disable the built-in GraphQL Playground (a web IDE for working on GraphQL queries).
  playground: true

# The "built-in" vector source, for accepting logs from the vector agents.
# Will be added by default, unless explicitly disabled.
# DEPRECATED. Use customConfig instead
vectorSource:
  # Disable to omit the vector source from being added.
  enabled: true
  # The name to use for the "built-in" vector source.
  sourceId: vector
  # The address to listen at.
  listenAddress: "0.0.0.0"
  # The port to listen at.
  listenPort: "9000"
  # Additional config to embed at the vector source.
  config:
    version: "2"
  # Specific node port to bind (useful if `service.type` is set to `NodePort`).
  nodePort: null  # 9090 (must be a number)
  # Raw TOML config to embed at the vector source (deprecated).
  rawConfig: null

# The "built-in" internal metrics source emitting Vector's internal opertaional
# metrics.
# DEPRECATED. Use customConfig instead
internalMetricsSource:
  # Disable to omit the internal metrics source from being added.
  enabled: true
  # The name to use for the "built-in" internal metrics source.
  sourceId: internal_metrics
  # Additional config to embed at the internal metrics source.
  config: {}
    # option: "value"
  # Raw TOML config to embed at the internal metrics source (deprecated).
  rawConfig: null

# The "built-in" prometheus sink exposing metrics in the Prometheus scraping
# format.
# When using this "built-in" sink, we automatically configure container ports,
# and ensure things are ready for discovery and scraping via Prometheus'
# `kubernetes_sd_configs` jobs.
# DEPRECATED. Use customConfig instead
prometheusSink:
  # Disable to omit the prometheus sink from being added.
  enabled: true
  # The name to use for the "built-in" prometheus sink.
  sinkId: prometheus_sink
  # Inputs of the built-in prometheus sink.
  # If you have built-in internal metrics source enabled, we'll add it as a
  # input here under the hood, so you don't have to pass it here.
  # Unless `excludeInternalMetrics` is set to `true`, in which case you're
  # responsible of wiring up the internal metrics.
  inputs: []
  # Set this to `true` to opt-out from automatically adding the built-in
  # internal metrics source to the inputs.
  excludeInternalMetrics: false
  # The address to listen at.
  listenAddress: "0.0.0.0"
  # The port to listen at.
  listenPort: "9090"
  # Additional config to embed at the prometheus sink.
  config: {}
    # option: "value"
  # Raw TOML config to embed at the prometheus sink (deprecated).
  rawConfig: null
  # Add Prometheus annotations to Pod to opt-in for Prometheus scraping.
  # To be used in clusters that rely on Pod annotations in the form of
  # `prometheus.io/scrape` to discover scrape targets.
  addPodAnnotations: false
  # Use prometheus-operator `PodMonitor` to opt-in for Prometheus scraping.
  # To be used in clusters that rely on prometheus-operator to gather metrics.
  # You might want to set `podMonitorSelectorNilUsesHelmValues=false` if you're
  # using prometheus-operator Helm chart to allow `PodMonitor` resources
  # discovery in all namespaces.
  podMonitor:
    # Whether to add the `PodMonitor` resource or not.
    # `prometheus-operator` CRDs are necessary, otherwise you'll get an error.
    enabled: false
    # Additional labels for PodMonitor
    additionalLabels: {}
    # Additional relabelings to include in the `PodMonitor`.
    extraRelabelings: []
    # metricRelabelings to include in the `PodMonitor`.
    metricRelabelings: []

# Sources to add to the generated `vector` config
# DEPRECATED. Use customConfig instead
sources: {}
  # source_name:
  #   type: "source_type"
  #   rawConfig: |
  #     option = "value"

# Transforms to add to the generated `vector` config.
# DEPRECATED. Use customConfig instead
transforms: {}
  # transform_name:
  #   type: "transform_type"
  #   inputs: ["input1", "input2"]
  #   rawConfig: |
  #     option = "value"

# Sinks to add to the generated `vector` config.
# DEPRECATED. Use customConfig instead
sinks: {}
  # sink_name:
  #   type: "sink_type"
  #   inputs: ["input1", "input2"]
  #   rawConfig: |
  #     option = "value"

haproxy:
  enabled: false
  ## Default values for HAProxy
  ## The included templates and values are heavily influenced by the haproxytech/haproxy chart
  ## ref: https://github.com/haproxytech/helm-charts/tree/main/haproxy

  ## Configure Service Account
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  serviceAccount:
    create: true
    name:

  ## Default values for image
  image:
    repository: haproxytech/haproxy-alpine
    tag: 2.4.0
    pullPolicy: IfNotPresent

  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
  replicaCount: 1

  ## Init Containers
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  initContainers: []
  # - name: sysctl
  #   image: "busybox:musl"
  #   command:
  #     - /bin/sh
  #     - -c
  #     - sysctl -w net.core.somaxconn=65536
  #   securityContext:
  #     privileged: true

  ## Pod termination grace period
  ## ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/
  terminationGracePeriodSeconds: 60

  ## Deployment strategy definition
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  strategy: {}
  #  rollingUpdate:
  #    maxSurge: 25%
  #    maxUnavailable: 25%
  #  type: RollingUpdate

  ## Pod PriorityClass
  ## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass
  priorityClassName: ""

  ## Additional volumeMounts to the controller main container
  extraVolumeMounts: []
  ## Example empty volume mounts when using securityContext->readOnlyRootFilesystem
  # - name: etc-haproxy
  #   mountPath: /etc/haproxy
  # - name: tmp
  #   mountPath: /tmp
  # - name: var-state-haproxy
  #   mountPath: /var/state/haproxy

  ## Additional volumes to the controller pod
  extraVolumes: []
  ## Example empty volumes when using securityContext->readOnlyRootFilesystem
  # - name: etc-haproxy
  #   emptyDir: {}
  # - name: tmp
  #   emptyDir: {}
  # - name: var-state-haproxy
  #   emptyDir: {}

  ## HAProxy daemon configuration
  # ref: https://www.haproxy.org/download/2.2/doc/configuration.txt
  config: |
    global
      log stdout local0
      maxconn 4096
      stats socket /tmp/haproxy
      hard-stop-after {{ .Values.haproxy.terminationGracePeriodSeconds }}s

    defaults
      log     global
      option  dontlognull
      retries 3
      option  redispatch
      option  allbackups
      timeout client 5s
      timeout server 5s
      timeout connect 5s

    resolvers coredns
      nameserver dns1 {{ .Values.global.kubeDNSAddress }}.svc.{{ .Values.global.clusterDomain }}:53
      resolve_retries 3
      timeout resolve 2s
      timeout retry 1s
      accepted_payload_size 8192
      hold valid 10s
      hold obsolete 15s

    frontend stats
      mode http
      bind :::1024
      http-request use-service prometheus-exporter if { path /metrics }
    {{ include "haproxy.vectorConfig" . }}

  ## Additional secrets to mount as volumes
  ## This is expected to be an array of dictionaries specifying the volume name, secret name and mount path
  mountedSecrets: []
  #  - volumeName: ssl-certificate
  #    secretName: star-example-com
  #    mountPath: /usr/local/etc/ssl

  ## Pod Node assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  nodeSelector: {}

  ## Node Taints and Tolerations for pod-node cheduling through attraction/repelling
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []
  #  - key: "key"
  #    operator: "Equal|Exists"
  #    value: "value"
  #    effect: "NoSchedule|PreferNoSchedule|NoExecute(1.6 only)"

  ## Node Affinity for pod-node scheduling constraints
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}

  ## Additional labels to add to the pod container metadata
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  podLabels: {}
  #  key: value

  ## Additional annotations to add to the pod container metadata
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  podAnnotations: {}
  #  key: value
  #

  ## Disableable use of Pod Security Policy
  ## ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/
  podSecurityPolicy:
    create: true

  ## Pod Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  podSecurityContext: {}

  ## Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  securityContext:
    enabled: false
    runAsUser: 1000
    runAsGroup: 1000

  ## Compute Resources
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  resources:
  #  limits:
  #    cpu: 100m
  #    memory: 64Mi
    requests:
      cpu: 100m
      memory: 64Mi

  ## Service configuration
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
  service:
    type: ClusterIP   # can be 'LoadBalancer'

    ## Service ClusterIP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    clusterIP: ""

    ## LoadBalancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer
    loadBalancerIP: ""

    ## Source IP ranges permitted to access Network Load Balancer
    # ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/
    loadBalancerSourceRanges: []

    ## Service annotations
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
    annotations: {}
