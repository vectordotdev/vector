---
last_modified_on: "2020-05-21"
delivery_guarantee: "best_effort"
component_title: "File"
description: "The Vector [`file`](#file) source ingests data through one or more local files and outputs `log` events."
event_types: ["log"]
function_category: "collect"
issues_url: https://github.com/timberio/vector/issues?q=is%3Aopen+is%3Aissue+label%3A%22source%3A+file%22
operating_systems: ["Linux","MacOS","Windows"]
sidebar_label: "file|[\"log\"]"
source_url: https://github.com/timberio/vector/tree/master/src/sources/file
status: "prod-ready"
title: "File Source"
unsupported_operating_systems: []
---

import Alert from '@site/src/components/Alert';
import Fields from '@site/src/components/Fields';
import Field from '@site/src/components/Field';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

The Vector [`file`](#file) source
ingests data through one or more local files and outputs
[`log`][docs.data-model.log] events.

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the template located at:

     website/docs/reference/sources/file.md.erb
-->

## Requirements

<Alert icon={false} type="danger" className="list--icons list--icons--warnings">

* This component must be provided access to the configured file system.

</Alert>

## Configuration

<Tabs
  block={true}
  defaultValue="common"
  values={[{"label":"Common","value":"common"},{"label":"Advanced","value":"advanced"}]}>
<TabItem value="common">

```toml title="vector.toml"
[sources.my_source_id]
  # General
  type = "file" # required
  ignore_older = 86400 # optional, no default, seconds
  include = ["/var/log/nginx/*.log"] # required
  start_at_beginning = false # optional, default

  # Priority
  oldest_first = false # optional, default
```

</TabItem>
<TabItem value="advanced">

```toml title="vector.toml"
[sources.my_source_id]
  # General
  type = "file" # required
  data_dir = "/var/lib/vector" # optional, no default
  exclude = ["/var/log/nginx/*.[0-9]*.log"] # optional, no default
  glob_minimum_cooldown = 1000 # optional, default, milliseconds
  ignore_older = 86400 # optional, no default, seconds
  include = ["/var/log/nginx/*.log"] # required
  max_line_bytes = 102400 # optional, default, bytes
  start_at_beginning = false # optional, default

  # Context
  file_key = "file" # optional, default
  host_key = "host" # optional, default

  # Fingerprinting
  fingerprinting.fingerprint_bytes = 256 # optional, default, bytes, relevant when strategy = "checksum"
  fingerprinting.ignored_header_bytes = 0 # optional, default, bytes, relevant when strategy = "checksum"
  fingerprinting.strategy = "checksum" # optional, default

  # Multiline
  multiline.condition_pattern = "^[\\s]+" # required
  multiline.mode = "continue_through" # required
  multiline.start_pattern = "^[^\\s]" # required
  multiline.timeout_ms = 1000 # required, milliseconds

  # Priority
  max_read_bytes = 2048 # optional, default, bytes
  oldest_first = false # optional, default
```

</TabItem>
</Tabs>

<Fields filters={true}>
<Field
  common={false}
  defaultValue={null}
  enumValues={null}
  examples={["/var/lib/vector"]}
  groups={[]}
  name={"data_dir"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"string"}
  unit={null}
  warnings={[]}
  >

### data_dir

The directory used to persist file checkpoint positions. By default, the
[global [`data_dir`](#data_dir) option][docs.global-options#data_dir] is used. Please make
sure the Vector project has write permissions to this dir.
 See [Checkpointing](#checkpointing) for more info.


</Field>
<Field
  common={false}
  defaultValue={null}
  enumValues={null}
  examples={[["/var/log/nginx/*.[0-9]*.log"]]}
  groups={[]}
  name={"exclude"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"[string]"}
  unit={null}
  warnings={[]}
  >

### exclude

Array of file patterns to exclude. [Globbing](#globbing) is supported.*Takes
precedence over the [`include` option](#include).*



</Field>
<Field
  common={false}
  defaultValue={"file"}
  enumValues={null}
  examples={["file"]}
  groups={[]}
  name={"file_key"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"string"}
  unit={null}
  warnings={[]}
  >

### file_key

The key name added to each event with the full path of the file.
 See [Context](#context) for more info.


</Field>
<Field
  common={false}
  defaultValue={null}
  enumValues={null}
  examples={[]}
  groups={[]}
  name={"fingerprinting"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"table"}
  unit={null}
  warnings={[]}
  >

### fingerprinting

Configuration for how the file source should identify files.


<Fields filters={false}>
<Field
  common={false}
  defaultValue={256}
  enumValues={null}
  examples={[256]}
  groups={[]}
  name={"fingerprint_bytes"}
  path={"fingerprinting"}
  relevantWhen={{"strategy":"checksum"}}
  required={false}
  templateable={false}
  type={"uint"}
  unit={"bytes"}
  warnings={[]}
  >

#### fingerprint_bytes

The number of bytes read off the head of the file to generate a unique
fingerprint.
 See [Fingerprinting](#fingerprinting) for more info.


</Field>
<Field
  common={false}
  defaultValue={0}
  enumValues={null}
  examples={[0]}
  groups={[]}
  name={"ignored_header_bytes"}
  path={"fingerprinting"}
  relevantWhen={{"strategy":"checksum"}}
  required={false}
  templateable={false}
  type={"uint"}
  unit={"bytes"}
  warnings={[]}
  >

#### ignored_header_bytes

The number of bytes to skip ahead (or ignore) when generating a unique
fingerprint. This is helpful if all files share a common header.
 See [Fingerprinting](#fingerprinting) for more info.


</Field>
<Field
  common={false}
  defaultValue={"checksum"}
  enumValues={{"checksum":"Read [`fingerprint_bytes`](#fingerprint_bytes) bytes from the head of the file to uniquely identify files via a checksum.","device_and_inode":"Uses the [device and inode][urls.inode] to unique identify files."}}
  examples={["checksum","device_and_inode"]}
  groups={[]}
  name={"strategy"}
  path={"fingerprinting"}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"string"}
  unit={null}
  warnings={[]}
  >

#### strategy

The strategy used to uniquely identify files. This is important for
[checkpointing](#checkpointing) when file rotation is used.



</Field>
</Fields>

</Field>
<Field
  common={false}
  defaultValue={1000}
  enumValues={null}
  examples={[1000]}
  groups={[]}
  name={"glob_minimum_cooldown"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"uint"}
  unit={"milliseconds"}
  warnings={[]}
  >

### glob_minimum_cooldown

Delay between file discovery calls. This controls the interval at which Vector
searches for files.
 See [Auto Discovery](#auto-discovery) and [Globbing](#globbing) for more info.


</Field>
<Field
  common={false}
  defaultValue={"host"}
  enumValues={null}
  examples={["host"]}
  groups={[]}
  name={"host_key"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"string"}
  unit={null}
  warnings={[]}
  >

### host_key

The key name added to each event representing the current host. This can also
be globally set via the [global [`host_key`](#host_key)
option][docs.reference.global-options#host_key].
 See [Context](#context) for more info.


</Field>
<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={[86400]}
  groups={[]}
  name={"ignore_older"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"uint"}
  unit={"seconds"}
  warnings={[]}
  >

### ignore_older

Ignore files with a data modification date that does not exceed this age.



</Field>
<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={[["/var/log/nginx/*.log"]]}
  groups={[]}
  name={"include"}
  path={null}
  relevantWhen={null}
  required={true}
  templateable={false}
  type={"[string]"}
  unit={null}
  warnings={[]}
  >

### include

Array of file patterns to include. [Globbing](#globbing) is supported.
 See [File Read Order](#file-read-order) and [File Rotation](#file-rotation) for more info.


</Field>
<Field
  common={false}
  defaultValue={102400}
  enumValues={null}
  examples={[102400]}
  groups={[]}
  name={"max_line_bytes"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"uint"}
  unit={"bytes"}
  warnings={[]}
  >

### max_line_bytes

The maximum number of a bytes a line can contain before being discarded. This
protects against malformed lines or tailing incorrect files.



</Field>
<Field
  common={false}
  defaultValue={2048}
  enumValues={null}
  examples={[2048]}
  groups={[]}
  name={"max_read_bytes"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"uint"}
  unit={"bytes"}
  warnings={[]}
  >

### max_read_bytes

An approximate limit on the amount of data read from a single file at a given
time.



</Field>
<Field
  common={false}
  defaultValue={null}
  enumValues={null}
  examples={[]}
  groups={[]}
  name={"multiline"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"table"}
  unit={null}
  warnings={[]}
  >

### multiline

Multiline parsing configuration (per file).
If not speicified, multiline parsing is disabled.
 See [Multi-Line Messages](#multi-line-messages) for more info.

<Fields filters={false}>
<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={["^[\\s]+","\\\\$","^(INFO|ERROR) ",";$"]}
  groups={[]}
  name={"condition_pattern"}
  path={"multiline"}
  relevantWhen={null}
  required={true}
  templateable={false}
  type={"string"}
  unit={null}
  warnings={[]}
  >

#### condition_pattern

Condition regex pattern to look for. Exact behavior is configured via [`mode`](#mode).
 See [Multi-Line Messages](#multi-line-messages) for more info.


</Field>
<Field
  common={true}
  defaultValue={null}
  enumValues={{"continue_through":"All consecutive lines matching this pattern are included in the group. The first line (the line that matched the start pattern) does not need to match the `ContinueThrough` pattern. This is useful in cases such as a Java stack trace, where some indicator in the line (such as leading whitespace) indicates that it is an extension of the preceeding line.","continue_past":"All consecutive lines matching this pattern, plus one additional line, are included in the group. This is useful in cases where a log message ends with a continuation marker, such as a backslash, indicating that the following line is part of the same message.","halt_before":"All consecutive lines not matching this pattern are included in the group. This is useful where a log line contains a marker indicating that it begins a new message.","halt_with":"All consecutive lines, up to and including the first line matching this pattern, are included in the group. This is useful where a log line ends with a termination marker, such as a semicolon."}}
  examples={["continue_through","continue_past","halt_before","halt_with"]}
  groups={[]}
  name={"mode"}
  path={"multiline"}
  relevantWhen={null}
  required={true}
  templateable={false}
  type={"string"}
  unit={null}
  warnings={[]}
  >

#### mode

Mode of operation, specifies how the [`condition_pattern`](#condition_pattern) is interpreted.
 See [Multi-Line Messages](#multi-line-messages) for more info.


</Field>
<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={["^[^\\s]","\\\\$","^(INFO|ERROR) ","[^;]$"]}
  groups={[]}
  name={"start_pattern"}
  path={"multiline"}
  relevantWhen={null}
  required={true}
  templateable={false}
  type={"string"}
  unit={null}
  warnings={[]}
  >

#### start_pattern

Start regex pattern to look for as a beginning of the message.
 See [Multi-Line Messages](#multi-line-messages) for more info.


</Field>
<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={[1000,600000]}
  groups={[]}
  name={"timeout_ms"}
  path={"multiline"}
  relevantWhen={null}
  required={true}
  templateable={false}
  type={"uint"}
  unit={"milliseconds"}
  warnings={[]}
  >

#### timeout_ms

The maximum time to wait for the continuation. Once this timeout is reached,
the buffered message is guaraneed to be flushed, even if incomplete.



</Field>
</Fields>

</Field>
<Field
  common={true}
  defaultValue={false}
  enumValues={null}
  examples={[false,true]}
  groups={[]}
  name={"oldest_first"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"bool"}
  unit={null}
  warnings={[]}
  >

### oldest_first

Instead of balancing read capacity fairly across all watched files, prioritize
draining the oldest files before moving on to read data from younger files.
 See [File Read Order](#file-read-order) for more info.


</Field>
<Field
  common={true}
  defaultValue={false}
  enumValues={null}
  examples={[false,true]}
  groups={[]}
  name={"start_at_beginning"}
  path={null}
  relevantWhen={null}
  required={false}
  templateable={false}
  type={"bool"}
  unit={null}
  warnings={[]}
  >

### start_at_beginning

For files with a stored checkpoint at startup, setting this option to `true`
will tell Vector to read from the beginning of the file instead of the stored
checkpoint.
 See [Read Position](#read-position) for more info.


</Field>
</Fields>

## Fields

```javascript title="example log event"
{
  // ...
  "file": "/var/log/nginx.log",
  "host": "my.host.com",
  "message": "Started GET / for 127.0.0.1 at 2012-03-10 14:28:14 +0100",
  "timestamp": "2019-11-01T21:15:47+00:00"
  // ...
}
```

<Fields filters={true}>
<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={["/var/log/nginx.log"]}
  groups={[]}
  name={"file"}
  path={null}
  relevantWhen={null}
  required={true}
  templateable={false}
  type={"string"}
  unit={null}
  warnings={[]}
  >

### file

The _full_ path of the file tha the log originated from. This can be renamed
via the [`file_key`](#file_key) option.
 See [Checkpointing](#checkpointing) and [Context](#context) for more info.


</Field>
<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={["my.host.com"]}
  groups={[]}
  name={"host"}
  path={null}
  relevantWhen={null}
  required={true}
  templateable={false}
  type={"string"}
  unit={null}
  warnings={[]}
  >

### host

The current hostname, equivalent to the `gethostname` command. This can be
renamed via the [`host_key`](#host_key) option.



</Field>
<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={["Started GET / for 127.0.0.1 at 2012-03-10 14:28:14 +0100"]}
  groups={[]}
  name={"message"}
  path={null}
  relevantWhen={null}
  required={true}
  templateable={false}
  type={"string"}
  unit={null}
  warnings={[]}
  >

### message

The raw log message, unaltered. This can be renamed via the [global
`message_key` option][docs.reference.global-options#message_key].



</Field>
<Field
  common={true}
  defaultValue={null}
  enumValues={null}
  examples={["2019-11-01T21:15:47+00:00"]}
  groups={[]}
  name={"timestamp"}
  path={null}
  relevantWhen={null}
  required={true}
  templateable={false}
  type={"timestamp"}
  unit={null}
  warnings={[]}
  >

### timestamp

The exact time the event was ingested. This can be renamed via the [global
`timestamp_key` option][docs.reference.global-options#timestamp_key].



</Field>
</Fields>

## How It Works

### Auto Discovery

Vector will continually look for new files matching any of your include
patterns. The frequency is controlled via the [`glob_minimum_cooldown`](#glob_minimum_cooldown) option.
If a new file is added that matches any of the supplied patterns, Vector will
begin tailing it. Vector maintains a unique list of files and will not tail a
file more than once, even if it matches multiple patterns. You can read more
about how we identify files in the [Identification](#file-identification)
section.

### Checkpointing

Vector checkpoints the current read position in the file after each successful
read. This ensures that Vector resumes where it left off if restarted,
preventing data from being read twice. The checkpoint positions are stored in
the data directory which is specified via the
[global [`data_dir`](#data_dir) option][docs.global-options#data_dir] but can be
overridden via the [`data_dir`](#data_dir) option in the [`file`](#file) source directly.

### Compressed Files

Vector will transparently detect files which have been compressed using `gzip`
and decompress them for reading. This detection process looks for the unique
sequence of bytes in the `gzip` header and does not rely on the compressed files
adhering to any kind of naming convention.

One caveat with reading compressed files is that Vector is not able to
efficiently seek into them. Rather than implement a potentially-expensive full
scan as a seek mechanism, Vector currently will not attempt to make further
reads from a file for which it has already stored a checkpoint in a previous
run. For this reason, users should take care to allow Vector to fully process
any compressed files before shutting the process down or moving the files to
another location on disk.

### Context

By default, the [`file`](#file) source will add context
keys to your events via the [`file_key`](#file_key) and [`host_key`](#host_key)
options.

### Environment Variables

Environment variables are supported through all of Vector's configuration.
Simply add `${MY_ENV_VAR}` in your Vector configuration file and the variable
will be replaced before being evaluated.

You can learn more in the
[Environment Variables][docs.configuration#environment-variables] section.

### File Deletion

When a watched file is deleted, Vector will maintain its open file handle and
continue reading until it reaches `EOF`. When a file is no longer findable in
the `includes` glob and the reader has reached EOF, that file's reader is
discarded.

### File Read Order

By default, Vector attempts to allocate its read bandwidth fairly across all of
the files it's currently watching. This prevents a single very busy file from
starving other independent files from being read. In certain situations,
however, this can lead to interleaved reads from files that should be read one
after the other.

For example, consider a service that logs to timestamped file, creating
a new one at an interval and leaving the old one as-is. Under normal operation,
Vector would follow writes as they happen to each file and there would be no
interleaving. In an overload situation, however, Vector may pick up and begin
tailing newer files before catching up to the latest writes from older files.
This would cause writes from a single logical log stream to be interleaved in
time and potentially slow down ingestion as a whole, since the fixed total read
bandwidth is allocated across an increasing number of files.

To address this type of situation, Vector provides the [`oldest_first`](#oldest_first) flag. When
set, Vector will not read from any file younger than the oldest file that it
hasn't yet caught up to. In other words, Vector will continue reading from older
files as long as there is more data to read. Only once it hits the end will it
then move on to read from younger files.

Whether or not to use the [`oldest_first`](#oldest_first) flag depends on the organization of the
logs you're configuring Vector to tail. If your [`include`](#include) glob contains multiple
independent logical log streams (e.g. nginx's `access.log` and `error.log`, or
logs from multiple services), you are likely better off with the default
behavior. If you're dealing with a single logical log stream or if you value
per-stream ordering over fairness across streams, consider setting
`oldest_first` to `true`.

### File Rotation

Vector supports tailing across a number of file rotation strategies. The default
behavior of `logrotate` is simply to move the old log file and create a new one.
This requires no special configuration of Vector, as it will maintain its open
file handle to the rotated log until it has finished reading and it will find
the newly created file normally.

A popular alternative strategy is `copytruncate`, in which `logrotate` will copy
the old log file to a new location before truncating the original. Vector will
also handle this well out of the box, but there are a couple configuration options
that will help reduce the very small chance of missed data in some edge cases.
We recommend a combination of `delaycompress` (if applicable) on the logrotate
side and including the first rotated file in Vector's [`include`](#include) option. This
allows Vector to find the file after rotation, read it uncompressed to identify
it, and then ensure it has all of the data, including any written in a gap
between Vector's last read and the actual rotation event.

### Fingerprinting

By default, Vector identifies files by creating a [cyclic redundancy check
(CRC)][urls.crc] on the first 256 bytes of the file. This serves as a
fingerprint to uniquely identify the file. The amount of bytes read can be
controlled via the [`fingerprint_bytes`](#fingerprint_bytes) and [`ignored_header_bytes`](#ignored_header_bytes) options.

This strategy avoids the common pitfalls of using device and inode names since
inode names can be reused across files. This enables Vector to [properly tail
files across various rotation strategies][pages.index#correctness].

### Globbing

[Globbing][urls.globbing] is supported in all provided file paths, files will
be [autodiscovered](#auto-discovery) continually at a rate defined by the
`glob_minimum_cooldown` option.

### Line Delimiters

Each line is read until a new line delimiter (the `0xA` byte) or `EOF` is found.

### Multi-Line Messages

Sometimes a single log event will appear as multiple log lines. To handle this,
Vector provides a set of [`multiline`](#multiline) options. These options were carefully
thought through and will allow you to solve the simplest and most complex
cases. Let's look at a few examples:

#### Example 1: Ruby Exceptions

Ruby exceptions, when logged, consist of multiple lines:

```text
foobar.rb:6:in `/': divided by 0 (ZeroDivisionError)
  from foobar.rb:6:in `bar'
  from foobar.rb:2:in `foo'
  from foobar.rb:9:in `<main>'
```

To consume these lines as a single event, use the following Vector configuration:

```toml
[sources.my_file_source]
  type = "file"
  # ...

  [sources.my_file_source.multiline]
    start_pattern = "^[^\\s]"
    mode = "continue_through"
    condition_pattern = "^[\\s]+from"
    timeout_ms = 1000
```

* [`start_pattern`](#start_pattern), set to `^[^\\s]`, tells Vector that new multi-line events
  should _not_ start  with white-space.
* [`mode`](#mode), set to `continue_through`, tells Vector continue aggregating lines
  until the [`condition_pattern`](#condition_pattern) is no longer valid (excluding the invalid line).
* [`condition_pattern`](#condition_pattern), set to `^[\\s]+from`, tells Vector to continue
  aggregating lines if they start with white-space followed by `from`.

#### Example 2: Line Continuations

Some programming languages use the backslash (`\`) character to signal that a
line will continue on the next line:

```text
First line\
second line\
third line
```

To consume these lines as a single event, use the following Vector configuration:

```toml
[sources.my_file_source]
  type = "file"
  # ...

  [sources.my_file_source.multiline]
    start_pattern = "\\$"
    mode = "continue_past"
    condition_pattern = "\\$"
    timeout_ms = 1000
```

* [`start_pattern`](#start_pattern), set to `\\$`, tells Vector that new multi-line events
  start with lines that end in `\`.
* [`mode`](#mode), set to `continue_past`, tells Vector continue aggregating lines, plus
  one additional line, until [`condition_pattern`](#condition_pattern) is false.
* [`condition_pattern`](#condition_pattern), set to `\\$`, tells Vector to continue aggregating lines
  if they _end_ with a `\` character.

#### Example 3: Timestamps

Activity logs from services such as Elasticsearch typically begin with a
timestamp, followed by information on the specific activity, as in this example:

```text
[2015-08-24 11:49:14,389][ INFO ][env                      ] [Letha] using [1] data paths, mounts [[/
(/dev/disk1)]], net usable_space [34.5gb], net total_space [118.9gb], types [hfs]
```

To consume these lines as a single event, use the following Vector configuration:

```toml
[sources.my_file_source]
  type = "file"
  # ...

  [sources.my_file_source.multiline]
    start_pattern = "^\[[0-9]{4}-[0-9]{2}-[0-9]{2}"
    mode = "halt_before"
    condition_pattern = "^\[[0-9]{4}-[0-9]{2}-[0-9]{2}"
    timeout_ms = 1000
```

* [`start_pattern`](#start_pattern), set to `^\[[0-9]{4}-[0-9]{2}-[0-9]{2}`, tells Vector that
  new multi-line events start with a timestamp sequence.
* [`mode`](#mode), set to `halt_before`, tells Vector to continue aggregating lines as
  long as the [`condition_pattern`](#condition_pattern) does not match.
* [`condition_pattern`](#condition_pattern), set to `^\[[0-9]{4}-[0-9]{2}-[0-9]{2}`, tells Vector to
  continue aggregating up until a line starts with a timestamp sequence.

### Read Position

By default, Vector will read new data only for newly discovered files, similar
to the `tail` command. You can read from the beginning of the file by setting
the [`start_at_beginning`](#start_at_beginning) option to `true`.

Previously discovered files will be [checkpointed](#checkpointing), and the
read position will resume from the last checkpoint.


[docs.configuration#environment-variables]: /docs/setup/configuration/#environment-variables
[docs.data-model.log]: /docs/about/data-model/log/
[docs.global-options#data_dir]: /docs/reference/global-options/#data_dir
[docs.reference.global-options#host_key]: /docs/reference/global-options/#host_key
[docs.reference.global-options#message_key]: /docs/reference/global-options/#message_key
[docs.reference.global-options#timestamp_key]: /docs/reference/global-options/#timestamp_key
[pages.index#correctness]: /#correctness
[urls.crc]: https://en.wikipedia.org/wiki/Cyclic_redundancy_check
[urls.globbing]: https://en.wikipedia.org/wiki/Glob_(programming)
[urls.inode]: https://en.wikipedia.org/wiki/Inode
