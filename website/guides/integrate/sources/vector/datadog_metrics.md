---
last_modified_on: "2020-03-29"
$schema: "/.meta/.schemas/guides.json"
title: "Send metrics from Vector to Datadog"
description: "A simple guide to send metrics from Vector to Datadog in just a few minutes."
author_github: https://github.com/binarylogic
cover_label: "Vector to Datadog Metrics Integration"
tags: ["type: tutorial","domain: sources","domain: sinks","source: vector","sink: datadog_metrics"]
hide_pagination: true
---

import ConfigExample from '@site/src/components/ConfigExample';
import InstallationCommand from '@site/src/components/InstallationCommand';
import ServiceDiagram from '@site/src/components/ServiceDiagram';

Metrics are an _essential_ part of observing any
service; without them you are flying blind. But collecting and analyzing them
can be a real challenge -- especially at scale. Not only do you need to solve
the basic task of collecting your metrics, but you must do it
in a reliable, performant, and robust manner. Nothing is more frustrating than
having your metrics pipeline fall on it's face during an
outage, or even worse, disrupt more important services!

Fear not! In this guide we'll show you how to send send metrics from Vector to Datadog
and build a metrics pipeline that will be the backbone of
your observability strategy.

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the template located at:

     website/guides/integrate/sources/vector/datadog_metrics.md.erb
-->

## What We'll Accomplish

To be clear, here's everything we'll accomplish in this short guide:

<ol className="list--checks list--flush">
  <li>
    Accept data from another upstream Vector instance.
  </li>
  <li>
    Send metrics to Datadog.
    <ol>
      <li>Batch data to maximize throughput.</li>
      <li>Automatically retry failed requests, with backoff.</li>
      <li>Automatically aggregate metrics at the edge for improved performance.</li>
    </ol>
  </li>
  <li className="list--li--arrow list--li--pink text--bold">All in just a few minutes!</li>
</ol>

## How It Works

We'll be using [Vector][urls.vector_website] to accomplish this task. Vector
is a [popular][urls.vector_stars], lightweight, and
[ultra-fast][urls.vector_performance] utility for building observability
pipelines. It's written in [Rust][urls.rust], making it memory safe and
reliable. We'll be deploying Vector as a
[service][docs.strategies#service].

The [service deployment strategy][docs.strategies#service] treats Vector like a
separate service. It is desigend to receive data from an upstream source and
fan-out to one or more destinations.
For this guide, Vector will receive data from
Vector via Vector's
[`` source][docs.sources.vector].
The following diagram demonstrates how it works.

<ServiceDiagram
  platformName={null}
  sourceName={"vector"}
  sinkName={"datadog_metrics"} />

## Tutorial

<div className="steps steps--h3">
<ol>
<li>

### Install Vector

<InstallationCommand />

</li>
<li>

### Configure Vector

<ConfigExample
  format="toml"
  path="vector.toml"
  sourceName={"vector"}
  sinkName={"datadog_metrics"} />

</li>
<li>

### Start Vector

```bash
vector --config vector.toml
```

That's it! Simple and to the point. Hit `ctrl+c` to exit.

</li>
</ol>
</div>


[docs.sources.vector]: /docs/reference/sources/vector/
[docs.strategies#service]: /docs/setup/deployment/strategies/#service
[urls.rust]: https://www.rust-lang.org/
[urls.vector_performance]: https://vector.dev/#performance
[urls.vector_stars]: https://github.com/timberio/vector/stargazers
[urls.vector_website]: https://vector.dev
